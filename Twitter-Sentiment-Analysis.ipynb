{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üê¶ Twitter Sentiment Analysis\n",
    "\n",
    "This notebook performs **Sentiment Analysis on Twitter data** using **Text Mining** and **Machine Learning** techniques. Tweets are classified into **Positive**, **Negative**, **Neutral**, or **Irrelevant** categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train = pd.read_csv('/content/twitter_training.csv')\n",
    "val = pd.read_csv('/content/twitter_validation.csv')\n",
    "\n",
    "train.columns = ['id', 'information', 'type', 'text']\n",
    "val.columns = ['id', 'information', 'type', 'text']\n",
    "\n",
    "train_data = train.copy()\n",
    "val_data = val.copy()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "def preprocess_text(df):\n",
    "    df['lower'] = df['text'].str.lower()\n",
    "    df['lower'] = df['lower'].apply(lambda x: str(x))\n",
    "    df['lower'] = df['lower'].apply(lambda x: re.sub('[^A-Za-z0-9 ]+', ' ', x))\n",
    "    return df\n",
    "\n",
    "train_data = preprocess_text(train_data)\n",
    "val_data = preprocess_text(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud Visualization\n",
    "def plot_wordcloud(df, sentiment):\n",
    "    text = ''.join(df[df['type'] == sentiment]['lower'])\n",
    "    wordcloud = WordCloud(\n",
    "        max_font_size=100,\n",
    "        max_words=100,\n",
    "        background_color='black',\n",
    "        scale=10,\n",
    "        width=800,\n",
    "        height=800\n",
    "    ).generate(text)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{sentiment} Tweets WordCloud')\n",
    "    plt.show()\n",
    "\n",
    "for sentiment in ['Negative', 'Positive', 'Irrelevant', 'Neutral']:\n",
    "    plot_wordcloud(train_data, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Distribution Plot\n",
    "plot1 = train.groupby(['information', 'type']).count().reset_index()\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.barplot(data=plot1, x='information', y='id', hue='type')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Brand')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Distribution of Tweets per Brand and Type')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization & Stopwords\n",
    "tokens_text = [word_tokenize(str(word)) for word in train_data['lower']]\n",
    "tokens_counter = [item for sublist in tokens_text for item in sublist]\n",
    "print(\"Number of unique tokens:\", len(set(tokens_counter)))\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words (1-gram) + Logistic Regression\n",
    "bow_counts = CountVectorizer(tokenizer=word_tokenize, stop_words=stop_words, ngram_range=(1, 1))\n",
    "reviews_train, reviews_test = train_test_split(train_data, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_bow = bow_counts.fit_transform(reviews_train['lower'])\n",
    "X_test_bow = bow_counts.transform(reviews_test['lower'])\n",
    "y_train_bow = reviews_train['type']\n",
    "y_test_bow = reviews_test['type']\n",
    "\n",
    "model1 = LogisticRegression(C=1, solver='liblinear', max_iter=200)\n",
    "model1.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "test_pred = model1.predict(X_test_bow)\n",
    "print(\"1-gram Logistic Regression Accuracy (Test):\", accuracy_score(y_test_bow, test_pred) * 100)\n",
    "\n",
    "X_val_bow = bow_counts.transform(val_data['lower'])\n",
    "y_val_bow = val_data['type']\n",
    "val_pred = model1.predict(X_val_bow)\n",
    "print(\"1-gram Logistic Regression Accuracy (Validation):\", accuracy_score(y_val_bow, val_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words (1-4 gram) + Logistic Regression\n",
    "bow_counts_ngram = CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 4))\n",
    "X_train_bow_ng = bow_counts_ngram.fit_transform(reviews_train['lower'])\n",
    "X_test_bow_ng = bow_counts_ngram.transform(reviews_test['lower'])\n",
    "X_val_bow_ng = bow_counts_ngram.transform(val_data['lower'])\n",
    "\n",
    "model2 = LogisticRegression(C=0.9, solver='liblinear', max_iter=1500)\n",
    "model2.fit(X_train_bow_ng, y_train_bow)\n",
    "\n",
    "test_pred_ng = model2.predict(X_test_bow_ng)\n",
    "print(\"1-4 gram Logistic Regression Accuracy (Test):\", accuracy_score(y_test_bow, test_pred_ng) * 100)\n",
    "\n",
    "val_pred_ng = model2.predict(X_val_bow_ng)\n",
    "print(\"1-4 gram Logistic Regression Accuracy (Validation):\", accuracy_score(y_val_bow, val_pred_ng) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
